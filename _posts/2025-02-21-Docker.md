---
title: 'Utilize the Docker container'
date: 2025-02-21
permalink: /posts/2025/02/docker/
tags:
  - docker
  - env 
  - python
---

# **CUDA Docker Container Setup and Usage Guide**
This tutorial covers how to **build, run, attach, and detach** a CUDA-enabled Docker container supporting **three NVIDIA A6000 GPUs**.

## **1. Install NVIDIA Docker Support**
### **1.1 Install Docker (if not installed)**
```bash
curl -fsSL https://get.docker.com | sh
sudo systemctl start docker
sudo systemctl enable docker
```

### **1.2 Install NVIDIA Container Toolkit**
```bash
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \
sudo curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && \
echo "deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://nvidia.github.io/libnvidia-container/$distribution stable" | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list && \
sudo apt-get update

sudo apt-get install -y nvidia-container-toolkit
```
Restart Docker:
```bash
sudo systemctl restart docker
```

Verify GPU support:
```bash
docker run --rm --gpus all nvidia/cuda:12.2.0-base nvidia-smi
```
If it shows available GPUs, the setup is correct.

---

## **2. Build a CUDA-Enabled Docker Image**
Create a file named **Dockerfile**:

```dockerfile
# Base image with CUDA 12.2 and cuDNN 8
FROM nvidia/cuda:12.2.0-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PATH="/usr/local/cuda/bin:${PATH}"

# Install necessary packages
RUN apt-get update && apt-get install -y \
    git wget curl build-essential \
    python3 python3-pip python3-dev && \
    rm -rf /var/lib/apt/lists/*

# Install PyTorch with CUDA support
RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Set working directory
WORKDIR /workspace

CMD ["/bin/bash"]
```

### **2.1 Build the Docker Image**
```bash
docker build -t cuda-container .
```

---

## **3. Run the Container with GPU Support**
### **3.1 Run the Container Using 3 NVIDIA A6000 GPUs**
```bash
docker run --rm --gpus '"device=0,1,2"' -it cuda-container bash
```
- `--gpus '"device=0,1,2"'` â†’ Allocates three A6000 GPUs.
- `-it` â†’ Runs interactively.
- `--rm` â†’ Deletes the container when exited.

### **3.2 Run a Persistent Container**
If you want a reusable container:
```bash
docker run --gpus '"device=0,1,2"' --name cuda_env -it cuda-container bash
```
To restart later:
```bash
docker start -ai cuda_env
```

---

## **4. Attach & Detach from Running Containers**
### **4.1 Detach from a Running Container**
Inside the container, press:  
```bash
Ctrl + P, Ctrl + Q
```
This **keeps the container running** in the background.

### **4.2 List Running Containers**
```bash
docker ps
```

### **4.3 Reattach to a Running Container**
Find the container ID using `docker ps`, then run:
```bash
docker attach <container_id>
```
Or if you named your container:
```bash
docker attach cuda_env
```

---

## **5. Stop & Remove Containers**
### **5.1 Stop a Running Container**
```bash
docker stop <container_id>
```
or
```bash
docker stop cuda_env
```

### **5.2 Remove a Stopped Container**
```bash
docker rm <container_id>
```

---

This tutorial provides a complete workflow for **building, running, detaching, and reattaching CUDA containers**. ðŸš€ Let me know if you need further refinements!